# KHU Vision and Learning Reading Group <img src="KHU_UI.png" width="160" style="margin:40px; padding: 10px;" align="right">

Time
- Wednesday AM 10:00

Location 
- 211-1 Electronic Information College Building


<p align="center">
<img src="Summer_2023_Trinity_Gathering.jpg" width="800" align="center">
</p>


## Table of Contents

- [Current Schedule (Summer 2024)](#current-schedule)
- [Mailing List](#mailing-list)
- [Presenter](#presenters)
- [Previous Meetings](#previous-meetings)
- [Related Links](#related-links)
- [FAQ](#faq)
- [About Us](#about-us)
- [Suggested Papers](#suggested-papers)


## Current Schedule

### Reading Group: 
Please let  Ka Young Kim (uwrgoy7584 -at- khu -dot- ac -dot- kr) know what paper you are going to present, and **please** provide (name and year) of the conference the paper was accepted and summary by **Friday 11:59am** before your presentation.

Moreover, send the **presentation slides link** on  **Tuesday 11:59pm**.

This Summer we will have Two presenters each week. Presentation duration is up to the presenter (as long as it does not go over an hour).

| Date | Presenters | Topic |
|-------------|------------|--------|
| 07/10 | Myeongjun Oh <br /> Jongseo Lee |Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis? [[Zhu, Hanxin, et al., CVPR 2024](https://arxiv.org/pdf/2403.06092)] [[slides](https://docs.google.com/presentation/d/1MzDo-ZbETzDHxTJh084cba1tUzWObk1NAbGe8TYclJw/edit)] <br /> Label-free concept bottleneck models [[Oikarinen, Tuomas, et al., ICLR 2023](https://arxiv.org/pdf/2304.06129)] [[slides](https://khuackr-my.sharepoint.com/:p:/g/personal/jong980812_khu_ac_kr/EW90O-74PBZLhaYRGSqAI68B8VZePvQSXQJ6zvCPCTCSxA?rtime=qlx6S3ug3Eg)]|
| 07/17 | Young-Seob Won <br /> Ka Young Kim |Exploring Incompatible Knowledge Transfer in Few-shot Image Generation [[Yunqing Zhao et al., CVPR 2023](https://arxiv.org/pdf/2304.07574)] [[slides](https://github.com/user-attachments/files/16246335/20240717_readingGroup_RICK_yswon.pptx)] <br /> FreeU: Free Lunch in Diffusion U-Net [[Si, Chenyang, et al., CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.pdf)] [[slides](https://o365khu-my.sharepoint.com/:p:/g/personal/2024310990_office_khu_ac_kr/Eb-7x1KOlwpFieRJtwo8wjMBzrSrF4FjP85_X-ESwdjEqg?e=J1IOVM)]|
| 07/24 | Joohyun Chang <br /> Jun-Yeong Moon |Single-Stage Visual Query Localization in Egocentric Videos [[Jiang, Hanwen, et al., NeurIPS 2023](https://arxiv.org/pdf/2306.09324)] [[slides](https://docs.google.com/presentation/d/195xfmHAmkweGLlLy-FMUWfszE_5trEIJ/edit?usp=sharing&ouid=114628959552383124490&rtpof=true&sd=true)] <br /> Towards Model-Agnostic Dataset Condensation by Heterogeneous Models [J.-Y. Moon, et al., ECCV 2024] [[slides](https://docs.google.com/presentation/d/1fgtvl6Jk0xNfsVaXZGjkna4LF4BMV4QMaIOdtQ19tYs/edit?usp=sharing)]|
| 07/31 | - | No Reading Group üìñ|
| 08/07 | Ohsung Choo <br /> Min-Yeong Park |Poda: Prompt-driven zero-shot domain adaptation [[Fahes, Mohammad, et al, ICCV 2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf)] [[slides](https://docs.google.com/presentation/d/1I0AnEbdzOeelpYNHbBhuXbR_Hr_MyLCh87GgA-8_3EA/edit?usp=sharing)] <br /> Versatile Incremental Learning: Towards Class and Domain-Agnostic Incremental Learning [Min-Yeong Park, Jae-Ho Lee, and Gyeong-Moon Park, ECCV 2024] [[slides](https://docs.google.com/presentation/d/1wZT5QKxnuFWsBifh4tt7YWnkzxJbxouxrkFT3GhpmCc/edit?usp=sharing)]|
| 08/14 | KCCV 2023 | No Reading Group üìñ|
| 08/21 | Hyeonbae Kim <br /> Min-Jae Kim | Mask-Free Neuron Concept Annotation for Interpreting Neural Networks in Medical Domain [[H.B. Kim, Y.H. Ahn, S.T. Kim, MICCAI2024](https://www.arxiv.org/pdf/2407.11375)] [[slides](https://docs.google.com/presentation/d/1pU11dQvWKAwoLS3if5gvoBxm1wZG5uhg/edit?usp=sharing&ouid=115797261789728292501&rtpof=true&sd=true)] <br />  InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation [[X. Liu, et al., ICLR 2024](https://openreview.net/pdf?id=1k4yZbbDqX)] [[slides](https://docs.google.com/presentation/d/1gEWUkj8bWxg44fTLeJgV9__fX6627ilx/edit?usp=sharing&ouid=116591346679315800758&rtpof=true&sd=true\)|
| 08/28 | Jehyun Park <br /> Euijune Lee |[paper] [slides] <br /> [paper] [slides]|


## Mailing List

We use Google Groups to manage the mailing list: [(link)](https://groups.google.com/u/2/a/khu.ac.kr/g/khu-vision-and-learning-reading-group-g-groups). You can click "Join Group" when you sign in with your Kyung Hee University account.

## Presenters
Please let Ka Young Kim (uwrgoy7584 -at- khu -dot- ac -dot- kr) know what paper you are going to present, and **please** provide (name and year) of the conference the paper was accepted and summary by **Friday 11:59am** before your presentation.
Moreover, send the **presentation slides link** on  **Tuesday 11:59pm**.

* [AGI](https://agi.khu.ac.kr/index.html)
  - M.S. student : Jiwon Hwang / Jaeho Lee / Juwon Seo / Jun-Yeong Moon / Keonhee Park /  Seun-An Choe / Min-Yeong Park / Taeyoung Lee / Min-Jae Kim
  - UG student : Won-Jeong Lee / Young-Seob Won
* [AUGI](http://ailab.khu.ac.kr/)
  - Ph.D. student: Enki Cho / Yong Hyun Ahn
  - M.S. student : Minkuk Kim / Soyoun Won / Hyeonbae Kim / Yebin Ji / Ohsung Choo / Ka Young Kim
  - UG student : Soo Hyun Im / Heedong Kim / Jehyun Park
* [MLVC](https://sites.google.com/khu.ac.kr/mlvclab/home?authuser=0)
  - M.S. student : Myeongjun Oh
  - UG student : Euijune Lee
* [VLL](https://vll.khu.ac.kr/index.html)
  - M.S. student : Jongseo Lee / Geo Ahn / Soyeon Hong
  - UG student : Joohyun Chang / Soohyun Park / Yuri Kim
* Alumni
  - \[AGI] M.S. : Ahyung Shin / Sunghoon Lee
  - \[MLVC] M.S. : Junghun Cha / Taegoo Kang / Subin Yang
  - \[VLL] M.S. : Dongho Lee / Jongmin Shin / Hyogun Lee / Kyungho Bae


## Previous Meetings

- [Summer~Fall 2021](https://github.com/khuvll/reading_group/blob/main/2021_Summer_Fall_schedule.md)
- [Winter 2022](https://github.com/khuvll/reading_group/blob/main/2022_Winter_schedule.md)
- [Spring 2022](https://github.com/khuvll/reading_group/blob/main/2022_Spring_schedule.md)
- [Summer 2022](https://github.com/khuvll/reading_group/blob/main/2022_Summer_schedule.md)
- [Fall 2022](https://github.com/khuvll/reading_group/blob/main/2022_Fall_Winter_schedule.md)
- [Winter~Spring 2023](https://github.com/khuvll/reading_group/blob/main/2023_Winter_Spring_schedule.md)
- [Summer 2023](https://github.com/khuvll/reading_group/blob/main/2023_Summer_schedule.md)
- [Fall 2023](https://github.com/khuvll/reading_group/blob/main/2023_Fall_schedule.md)
- [Winter 2024](https://github.com/KHU-VLL/KHU_Vision_and_Learning_Reading_Group/blob/main/2024_Winter_schedule.md)
- [Spring 2024](https://github.com/KHU-VLL/KHU_Vision_and_Learning_Reading_Group/blob/main/2024_Spring_schedule.md)

## Related Links

#### Resources
- [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)
- [Awesome Action Recognition](https://github.com/jinwchoi/awesome-action-recognition)
- [Computer Vision Foundation open access](http://openaccess.thecvf.com/menu.py)

#### Similar reading group/seminars in other universities
- [MIT Vision Seminars](https://sites.google.com/view/visionseminar)
- [UIUC Vision Lunch](http://vision.cs.illinois.edu/vision_website/)
- [UT-Austin CV Reading Group](http://vision.cs.utexas.edu/readinggroup/)
- [CMU VASC Seminar Series](http://ri.cmu.edu/events/category/vasc-seminar-series/list/?tribe_paged=1&tribe_event_display=past)
- [CMU ML Reading Group](http://www.cs.cmu.edu/~aarti/SMLRG/schedule.html)
- [VT Vision and Learning Reading Group](https://github.com/vt-vl-lab/reading_group)
- [Îî•Îü¨Îãù ÎÖºÎ¨∏ ÏùΩÍ∏∞ Î™®ÏûÑ @ TensorFlow Korea Facebook Group](https://www.youtube.com/playlist?list=PLXiK3f5MOQ760xYLb2eWbtOKOwUC-bByj)

#### Advanced CV courses
- [Advanced Computer Vision](https://filebox.ece.vt.edu/~jbhuang/teaching/ece6554/sp17/index.html) (Jia-Bin Huang, Virginia Tech)
- [Object and Activity Recognition Seminar](https://sites.google.com/site/ucbcs29443/) (Trevor Darrell, UC Berkeley)
- [Visual Learning and Recognition](http://graphics.cs.cmu.edu/courses/16-824/2017_spring/) (Abhinav Gupta, CMU)
- [Visual Recognition](http://vision.cs.utexas.edu/381V-fall2016/) (Kristen Grauman, UT Austin)
- [Advanced Computer Vision](https://filebox.ece.vt.edu/~S16ECE6554/) (Devi Parikh, Georgia Tech)
- [Cutting-Edge Trends in Deep Learning and Recognition](http://slazebni.cs.illinois.edu/spring17) (Svetlana Lazebnik, UIUC)

## FAQ
#### How is the presenters' order generated?
The presenters' order is generated from the presenters' list in a FIFO manner (but the list is initially generated randomly).


#### What should I do if I can not present at the scheduled time?
Contact other presenters to see if they are willing to swap dates with you. Let the group organizer Ka Young Kim (uwrgoy7584 -at- khu -dot- ac -dot- kr) know about your situation.



## About Us

#### How it works?
We are a group that meets about once a week to discuss one to two relevant papers. For every meeting, two people will be in charge of selecting the paper(s) for that meeting, thoroughly understanding the work, and leading the discussion (either informally or via a presentation, whatever the leader thinks is best). The rest of the members will read over the paper(s) beforehand to gain a basic idea of the work. Then, on the day of the meeting, we will discuss the strengths, weaknesses, and techniques of the paper(s).

**NOTE:** Please tell the group organizer Ka Young Kim (uwrgoy7584 -at- khu -dot- ac -dot- kr) which paper(s) you are going to present, and summarize the paper/talk in several sentences, before the **Friday** of that week.

#### What we read?
We will be reading papers appearing in the leading computer vision conferences (e.g., CVPR, ICCV, ECCV, SIGGRAPH, SIGGRAPH Asia) and machine learning conferences (e.g., NeurIPS, ICML, ICLR), and other AI conferences (e.g., MICCAI, ACL, EMNLP, NAACL, UAI, AAAI, IJCAI, AISTATS). Members are free to choose which paper(s) they will present (we can also provide suggestions), thus the specific topics will vary based on the members' interests.

#### Who can join?
We are open to everyone who is interested, whether you are an undergrad, a grad student, or KHU staff, regardless of department. As long as you are interested in learning more about the fields (by reading cutting-edge research papers), you are welcome to join.

## Suggested Papers

We maintain a pool of suggested papers [here](https://docs.google.com/spreadsheets/d/1tEug71Jg0ucKJfyBy3qisrGZPR49HNdAPeHI1QCu-9A/edit?usp=sharing).

Credits: The contents and formats were modified from [VT Vision and Learning Reading Group](https://github.com/vt-vl-lab/reading_group).
