# KHU Vision and Learning Reading Group <img src="KHU_UI.png" width="240" align="right">

Time
- Friday 12:00PM - 1:00PM

Location
- 309, Electronic Information College Building, 1732, Deogyeong-daero, Giheung-gu, Yongin-si, Gyeonggi-do, Rep. of Korea, 17104
- You can join via zoom if you prefer (link will be provided via email)


## Table of Contents

- [Current Schedule (Summer 2021)](#current-schedule)
- [Mailing List](#mailing-list)
- [Presenter](#presenters)
- [Related Links](#related-links)
- [FAQ](#faq)
- [About Us](#about-us)
- [Suggested Papers](#suggested-papers)


## Current Schedule

### Reading Group: 
Please let Ah-Hyung (dkgud111 -at- khu -dot- ac -dot- kr) know what paper you are going to present and provide your summary by **Wednesday** before your presentation.

This semester we will have one presenter each week. Presentation duration is left up to the presenter (as long as it spans no more than one hour).

| Date       | Presenters     |  Topic     |
|-------------|--------|--------|
| 07/07 | [Jinwoo Choi](https://sites.google.com/site/jchoivision/)  | Why Can’t I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition [[Choi et al., NeurIPS 2019](https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F1912.05534&sa=D&sntz=1&usg=AFQjCNGrF3B6tCj4cJ7DraA85jgBxTQtTw)]  <br /> Learning Representational Invariances for Data-Efficient Action Recognition [[Choi et al., arXiv 2021](https://arxiv.org/abs/2103.16565)] [[slides](https://drive.google.com/file/d/1KHNloRmLGfzsceWSeGMQONzm-Pify1QQ/view?usp=sharing)] |
| 07/14 |   [Seong-Tae Kim](http://ailab.khu.ac.kr)   |  Neural Response Interpretation through the Lens of Critical Pathways [[Khakzar et al., CVPR 2021](https://arxiv.org/pdf/2103.16886.pdf)] [[slides](https://drive.google.com/file/d/1nMqlU9q7JCSHCs2q5sFLxmCAT67lpN1S/view?usp=sharing)]  |
| 07/21 |   Ah-Hyung Shin <br /> Dong-Ho Lee  |  MineGAN: effective knowledge transfer from GANs to target domains with few images [[Wang, Yaxing, et al., CVPR 2020](https://arxiv.org/abs/1912.05270)] [[slides](https://drive.google.com/file/d/1_Uc0RXnvAbLmCd2dD74bk2WMIRnKPQff/view?usp=sharing)] <br /> MLP-Mixer: An all-MLP Architecture for Vision [[Ilya Tolstikhin et al., arXiv 2021](https://arxiv.org/abs/2105.01601)] [[slides](https://drive.google.com/file/d/140spkEJsNVZQVKJoPSp-4yRyvzRNg-gh/view?usp=sharing)] |
| 07/28 |   Jae-Ho Lee  <br />   En-Ki Cho  |  Swin Transformer: Hierarchical Vision Transformer using Shifted Windows [[Liu, Ze, et al., arXiv 2021](https://arxiv.org/abs/2103.14030)] [[slides](https://drive.google.com/file/d/1IvrqeY0iZAd7pWFBWMwiOz4VEmuE7z-W/view?usp=sharing)] <br /> Understanding deep networks via extremal perturbations and smooth masks [[Fong, Ruth et al., IEEE/CVF 2019](https://arxiv.org/abs/1910.08485)] [[slides](https://drive.google.com/file/d/1kkdooaqgzGapwhsySNVoYokvJgAPz8z5/view?usp=sharing)] |
| 08/04 |   Sung-Hoon Lee  <br />  Jong-Min (Paul) Shin   |  Semantic-Aware Knowledge Distillation for Few-Shot Class-Incremental Learning [[Ali Cheraghian, et al., CVPR 2021](https://arxiv.org/abs/2103.04059)] [[slides](https://drive.google.com/file/d/13VKvVUk5lMtfRggaUZeB_N-JQ45fWwdz/view?usp=sharing)] <br/> Feature Pyramid Networks for Object Detection [[Lin, Tsung-Yi, et al., CVPR 2017](https://arxiv.org/abs/1612.03144)] [[slides](https://drive.google.com/file/d/1CNC3QLL3sho47MvJejtqPqDk_e9bIjZr/view?usp=sharing)] |
| 08/11 |   Jun-Yeong Park <br /> Gyeong-Ho Bae   |  Reducing catastrophic forgetting with learning on synthetic data [[Wojciech Masarczyk, Ivona Tautkute, CVPR Workshops 2020](https://arxiv.org/pdf/2004.14046.pdf)] [[slides](https://drive.google.com/file/d/1qksMlZyA7s1L1KX5q27cmjWLByDJE6xz/view?usp=sharing)] <br /> Is Space-Time Attention All You Need for Video Understanding? [[Gedas Bertasius et al., ICML 2021](https://arxiv.org/abs/2102.05095)] [[slides](https://drive.google.com/file/d/1S8wL2a4cgfJQldRAs7g3XSubxKXaDQ_3/view?usp=sharing)]  |
| 08/18 |   Ah-Hyung Shin <br /> Dong-Ho Lee   |  Parameter Efficient Multimodal Transformers for Video Representation Learning [[Lee, Sangho, et al., ICLR 2021](https://arxiv.org/abs/2012.04124)] [[slides](https://drive.google.com/file/d/1-H6DhMo7kKwV8lPGxzAWuZJWtD0X7p0B/view?usp=sharing)] <br /> Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles [[Mehdi Noroozi et al., ECCV 2016](https://arxiv.org/pdf/1603.09246.pdf)] [[slides](https://drive.google.com/file/d/1n9YmuJeOtMPcnTPzVnhmAMXqRnPQMs-a/view?usp=sharing)]  |
| 08/25 |   Jae-Ho Lee  <br />   En-Ki Cho   |  Training data-efficient image transformers & distillation through attention [[Touvron, Hugo, et al., ICML 2021](http://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf)] [[slides](https://drive.google.com/file/d/1z-V4EhwUV_6D3G03hIlmwGF2zcNbONO3/view?usp=sharing)] <br /> Restricting the Flow: Information Bottlenecks for Attribution [[Schulz, Karl, et al., ICLR 2020](https://arxiv.org/abs/2001.00396)] [[slides](https://drive.google.com/file/d/1VD59Ikzu3Xh1-yxF1hUPUsIiVII9aDki/view?usp=sharing)]|
| 09/03 |   Sung-Hoon Lee   |  Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation [[Mengyao Zhai, et al., ECCV 2020](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660392.pdf)] [[slides](https://drive.google.com/file/d/1Hp3bevABMgI9izgUHSbaqJayJeP3zYAT/view?usp=sharing)]  |
| 09/10 |   Jong-Min (Paul) Shin    |  EfficientNetV2: Smaller Models and Faster Training [[Tan, Mingxing, et al., ICML 2021](https://arxiv.org/pdf/2104.00298.pdf)] [[slides](https://docs.google.com/presentation/d/1EZwInktVGFYlb-OOqb5XTW7Na3fhjMoD0femmpd8908/edit?usp=sharing)]  |
| 09/17 |   Jun-Yeong Park  |  Few-Shot Lifelong Learning [[Pratik Mazumder, et al, AAAI 2021](https://www.cse.iitk.ac.in/users/piyush/papers/fsll_aaai2021.pdf)] [[slides](https://drive.google.com/file/d/1QfiBmMjxOdHfqczPNqoSXcQPGhfuyiKk/view?usp=sharing)]  |
| 09/24 |   Gyeong-Ho Bae   |  Large-Scale Long-Tailed Recognition in an Open World [[Z Liu et al., CVPR 2019](https://arxiv.org/pdf/1904.05160.pdf)] [slides]  |
| 10/01 |   Hyo-Gun Lee     |  [pdf] [slides]  |
| 10/08 |   Gun-Hee Park    |  [pdf] [slides]  |
| 10/15 |   Ju-Hye Son      |  [pdf] [slides]  |
| 10/22 |   -      |  No Meeting (Mid-Term Exam)  |
| 10/29  | Ah-Hyung Shin |[pdf] [slides]|
| 11/05  | Dong-Ho Lee |[pdf] [slides]|
| 11/12  | Jae-Ho Lee|[pdf] [slides]|
| 11/19  | Min-Guk Kim|[pdf] [slides]|
| 11/26  | En-Ki Cho|[pdf] [slides]|
| 12/03  | Sung-Hoon Lee|[pdf] [slides]|
| 12/10  | Jong-Min (Paul) Shin|[pdf] [slides]|
| 12/17  | - |  No Meeting (Final Exam)  ||

## Mailing List

We use Google Groups to manage the mailing list: [(link)](https://groups.google.com/u/2/a/khu.ac.kr/g/khu-vision-and-learning-reading-group-g-groups). You can click "Join Group" when you sign in with your Kyung Hee University account.

## Presenters
Please let Ah-Hyung (dkgud111 -at- khu -dot- ac -dot- kr)  know what paper you are going to present and provide your summary by **Wednesday** before your presentation. Also, please send your slides or a link to them once you finish preparing them.
 
* Dong-Ho Lee
* Jong-Min (Paul) Shin
* Gyeong-Ho Bae
* Hyo-Gun Lee
* En-Ki Cho
* Min-Guk Kim 
* Ah-Hyung Shin
* Jae-Ho Lee
* Jun-Yeong Park
* Sung-Hoon Lee
* Gun-Hee Park
* Ju-Hye Son
* [Prof. Jinwoo Choi](https://sites.google.com/site/jchoivision/) 
* [Prof. Seong-Tae Kim](http://ailab.khu.ac.kr)
* [Prof. Gyeong-Moon Park](http://agi.khu.ac.kr/)
* others...

Please contact Ah-Hyung (dkgud111 -at- khu -dot- ac -dot- kr) if you want to be a presenter this semester (2021 Summer and Fall)!

## Related Links

#### Resources
- [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)
- [Awesome Action Recognition](https://github.com/jinwchoi/awesome-action-recognition)
- [Computer Vision Foundation open access](http://openaccess.thecvf.com/menu.py)

#### Similar reading group/seminars in other universities
- [MIT Vision Seminars](https://sites.google.com/view/visionseminar)
- [UIUC Vision Lunch](http://vision.cs.illinois.edu/vision_website/)
- [UT-Austin CV Reading Group](http://vision.cs.utexas.edu/readinggroup/)
- [CMU VASC Seminar Series](http://ri.cmu.edu/events/category/vasc-seminar-series/list/?tribe_paged=1&tribe_event_display=past)
- [CMU ML Reading Group](http://www.cs.cmu.edu/~aarti/SMLRG/schedule.html)
- [VT Vision and Learning Reading Group](https://github.com/vt-vl-lab/reading_group)
- [딥러닝 논문 읽기 모임 @ TensorFlow Korea Facebook Group](https://www.youtube.com/playlist?list=PLXiK3f5MOQ760xYLb2eWbtOKOwUC-bByj)

#### Advanced CV courses
- [Advanced Computer Vision](https://filebox.ece.vt.edu/~jbhuang/teaching/ece6554/sp17/index.html) (Jia-Bin Huang, Virginia Tech)
- [Object and Activity Recognition Seminar](https://sites.google.com/site/ucbcs29443/) (Trevor Darrell, UC Berkeley)
- [Visual Learning and Recognition](http://graphics.cs.cmu.edu/courses/16-824/2017_spring/) (Abhinav Gupta, CMU)
- [Visual Recognition](http://vision.cs.utexas.edu/381V-fall2016/) (Kristen Grauman, UT Austin)
- [Advanced Computer Vision](https://filebox.ece.vt.edu/~S16ECE6554/) (Devi Parikh, Georgia Tech)
- [Cutting-Edge Trends in Deep Learning and Recognition](http://slazebni.cs.illinois.edu/spring17) (Svetlana Lazebnik, UIUC)

## FAQ
#### How is the presenters' order generated?
The presenters' order is generated from the presenters' list in a FIFO manner (but the list is initially generated randomly).

#### Who is responsible if I can not present at the scheduled time?
Yourself.

#### What should I do if I can not present at the scheduled time?
As early as possible, let the group organizer Ah-Hyung (dkgud111 -at- khu -dot- ac -dot- kr) know about your situation. Also contact other presenters to see if they are willing to swap dates with you.

#### I have a question not listed here...
Then ask by sending an e-mail to the mailing list (khu-vision-and-learning-reading-group-g-groups -at- khu -dot- ac -dot- kr).

## About Us

#### How it works?
We are a group that meets about once a week to discuss one to two relevant papers. For every meeting, two people will be in charge of selecting the paper(s) for that meeting, thoroughly understanding the work, and leading the discussion (either informally or via a presentation, whatever the leader thinks is best). The rest of the members will read over the paper(s) beforehand to gain a basic idea of the work. Then, on the day of the meeting, we will discuss the strengths, weaknesses, and techniques of the paper(s).

**NOTE:** Please tell the group organizer Ah-Hyung (dkgud111 -at- khu -dot- ac -dot- kr) which paper(s) you are going to present, and summarize the paper/talk in several sentences, before the **Wednesday** of that week.

#### What we read?
We will be reading papers appearing in the leading computer vision conferences (e.g., CVPR, ICCV, ECCV, SIGGRAPH, SIGGRAPH Asia) and machine learning conferences (e.g., NeurIPS, ICML, ICLR), and other AI conferences (e.g., MICCAI, ACL, EMNLP, NAACL, UAI, AAAI, IJCAI, AISTATS). Members are free to choose which paper(s) they will present (we can also provide suggestions), thus the specific topics will vary based on the members' interests.

#### Who can join?
We are open to everyone who is interested, whether you are an undergrad, a grad student, or KHU staff, regardless of department. As long as you are interested in learning more about the fields (by reading cutting-edge research papers), you are welcome to join.

## Suggested Papers

We maintain a pool of suggested papers [here](https://docs.google.com/spreadsheets/d/1tEug71Jg0ucKJfyBy3qisrGZPR49HNdAPeHI1QCu-9A/edit?usp=sharing).

Credits: The contents and formats were modified from [VT Vision and Learning Reading Group](https://github.com/vt-vl-lab/reading_group).
